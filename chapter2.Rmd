# RStudio Exercise 2

This week I have done quite a bit of DataCamp practices. So much so that I went on to next weeks' DataCamp practices as DataCamp's bottom grey-blue bar indicator of the progress was showing five distinct chapters. I did not release that one bar was for one week. This made me stress quite a bit as there didn't seem to be an end to the DataCamp practices. 

Unfortunately I have not managed to start reading the recommended reading material this week, which I really know I should.

I started the exercises too late.

*Describe the work you have done this week and summarize your learning.*

- Describe your work and results clearly. 
- Assume the reader has an introductory course level understanding of writing and reading R code as well as statistical methods.
- Assume the reader has no previous knowledge of your data or the more advanced methods you are using.

```{r}
date()
```

## 1. Read the data

Read the data file to an object.
Display the object (data table).

```{r}
# Read the data
learning2014 <- read.table(
  file = "http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/learning2014.txt",
  header = TRUE,
  sep = ",")

# check first few lines of the read data... table
head(learning2014)
```
Looking at the table, note to prior Data Wrangling part: attitude should have been scaled (divided by 10) as in DataCamp exercises. Exercise instructions were unclear on this (in the Data Wranglin part).

Check data dimensionality:

```{r}
dim(learning2014)
```

Check data structure: 

```{r}
str(learning2014)
```
Dataset is from a questionaire study, "international survey of Approaches to Learning". Check [here](https://www.mv.helsinki.fi/home/kvehkala/JYTmooc/JYTOPKYS3-meta.txt). 

**"gender"** is sex/gender of the questionaire participant. Data type is character (chr).  
**"age"** is the age of the participant in year (presumably). Data type is integer (int).  
**"attitude"** is "Global attitude toward statistics" divided by 10. Data type is integer (int).  
**"deep"** is a mean value of the following original variables: "D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31", summarizing deep learning of the participant. Data type is numeric (can be numbers with decimals).  
**stra** is a mean value of the following original variables: "ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28", summarizing strategic learning of the participant. Data type is numeric (can be numbers with decimals).  
**surf** is a mean value of the following original variables: "SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32, summarizing surface learning of the participant. Data type is numeric (can be numbers with decimals).  
**points** are exam points. Data type is integer (int).  

## 2. Graphical overview, summaries 

First we might need to install some packages to make some nice graphical overviews:

```{r}
# uncomment if you need to install
#install.packages("GGally", "ggplot2")
```

Let's start plotting some scatter plot matrix from our data:

```{r}
# access the GGally and ggplot2 libraries
library(GGally)
library(ggplot2)

# create a more advanced plot matrix with ggpairs()
p <- ggpairs(learning2014, mapping = aes(col = gender, alpha = 0.3), lower = list(combo = wrap("facethist", bins = 20)))

# draw the plot
p

```

As you can see the (multi)plot above is quite busy. Lots of information to take in.  
Let's start of by noting the column names above and row names on the right side. There is no legend for gender, but checking the plot there is F and M, F is for Female and M is for Male. So this plot is color coded by gender.

Top left corner, gender column and gender row, we can see the counts of each value.
F pinkish color, M cyan. We can see the female participant count is almost double the male count. Let's check this:

```{r}
table(learning2014$gender)
```
Top row (after gender to right) we have boxplots per each gender. Boxplot's describes the spread/distribution of values. The box part of boxplot describes interquartile range from Q1 (25th percentile) to Q3 (75th percentile), with the median (Q2/50th percentile) of values line in between Q1 and Q3. Circles describe possible outliers (as per presuming normal distribution of the values which is not always the case).

Left side (under gender), barplots display **value** of row (y-axis) to **count** of the values (x-axis) (AND BY GENDER).

Scatter plots (plots with points) are column values (x-axis) plotted against row values (y-axis).

We also have pairwise correlation information, one variable against another. Most interesting of teh correlations are Points and Attitude are positively correlated with each other. Deep learning and surface learning are negatively correlated with each other, but only with Males. So the values of these variables are somehow intertwined or in relation to each other.

Print summaries:

```{r}
summary(learning2014)
```

For numeric values of each variable we have the minimum and maximum value, mean. Median and 1st Quantile and 3rd Quantile are presented in boxplots (as previously explained). If the value distribution would be normal then 50% of the values would be inbetween Q1 and Q3 values.

## 3. Three variables as explanatory variables and fit a regression model 

Multiple regression model as there are more than three explanatory variables.

Let's have **deep**, **stra** and **surf** as explanatory variables for target variable **points**.

```{r}
# create multiple regression model
my_model <- lm(points ~ deep + stra + surf, data = learning2014)

# print out summary of the model
summary(my_model)
```
Does not seem too good. When doing multiple regression we are more interested in adjusted R-squared value, which is quite low, so the model doesn't really explain. Let's change up the model by switching one of the explanatory variables.

New model:

```{r}
my_model <- lm(points ~ attitude + stra + surf, data = learning2014)

# print out summary of the model
summary(my_model)
```
## 4. i) Explain the relationship between the chosen explanatory variables and the target variable (interpret the model parameters) ii) Explain and interpret the multiple R squared of the model

### i) Explain the relationship between the chosen explanatory variables and the target variable (interpret the model parameters

Increase of 1 exam point is associated with 0.339 increase in attitude points.
0.853 is estimated effect of strategic learning to exam points adjusting for attitude.
-0.586 is estimated effect of surface learning to exam points adjusting for attitude and strategic learning.

### ii) Explain and interpret the multiple R squared of the model

Adjusted R-squared is 0.1927, so almost 20% of variation in exam points can be explained by attitude, strategic learning and surface learning. Adjusted R-squared is the more important measure as we have multiple explanatory variables.

## 5. Plots: Residuals vs Fitted values, Normal QQ-plot and Residuals vs Leverage.

Let's produce the plots: Residual vs Fitted values, Normal QQ-plot and Residuals vs Leverage

```{r}
# create the model again just in case
my_model <- lm(points ~ attitude + stra + surf, data = learning2014)

# draw diagnostic plots using the plot() function. Choose the plots Residual vs Fitted values, Normal QQ-plot and Residuals vs Leverage (which are 1,2 and 5)
par(mfrow = c(2,2))
plot(my_model, which = c(1,2,5))

```

**Residuals vs Fitted:** Reasonable random spread of points. So there shouldn't be a problem with the assumptions.

**Normal Q-Q:** In the middle there seems to quite good fit to the normality line, but in the beginning and in the end there is a deviation from the line. So there isn't a reasonable with to the normality assumption.

**Residuals vs Leverage:** this plot can help to identify observations that have unusually high impact. There is seemingly few outlier values in the bottom of the plot. So these outliers may highly impact the model in question.
